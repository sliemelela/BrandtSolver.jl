# Theory
To understand how the package works, we will treat the algorithm proposed by
[Brandt_etal_2005](@cite) step by step.


## Goal of the algorithm
In this package we are treating a terminal wealth optimization problem.
More specifically, in this package we consider portfolio choice problems at timesteps
$n = 1, 2, \ldots, M$, where $M + 1$ is some terminal timestep.
This portfolio choice problem at timestep $n$ is defined by an investor who maximizes the expected utility
of their wealth at the terminal date $M$ by trading $N$ risky assets and a risk-free asset (cash).
Formally the investor's problem at timestep $n$ is
```math
    V_n(W_n, Z_n)
    = \max_{\{\omega_s\}_{s = n}^{M- 1}} \mathbb{E}_n[u(W_M)]
```
subject to the sequence of budget constraints
```math
    W_{m + 1} = W_s (\omega_s^\top R^e_{m + 1} + R_{m + 1})
```
for all $s \geq n$.
Here $R^e_{m + 1}$ can be interpreted as the excess return of the risky assets over the risk-ree
asset, and $R_{m + 1}$ is the gross return of other processes that _may_ depend on wealth
$W_m$.
Furthermore, $\{\omega_s\}_{s=n}^{M}$ is the sequence of portfolio weights chosen at times
$m = n, \ldots, M$ and $u$ is the investor's utility function.
The process $Z_n$ is a vector of state variables that are relevant for the investor's decision making.
Lastly, the function $u$ denotes the utility function of the investor.
The goal of this package is to find $\{\omega_s\}_{s=1}^{M}$

## Solution of the algorithm
The goal of this section is to give the final solution of the algorithm.
We acknowledge that the result can look quite daunting and so it is not the expectation that the
reader can immediately make sense of why the solution looks like it does.
Despite this, it can help to first see where we are working towards before explaining how it is
derived. Let us first start by specifying the notation.


### Notation
Let $\omega_m = (\omega^1_m, \ldots, \omega^N_m)$ be the components of the portfolio weights
at some timestep $m$ and write $R^e_{m + 1} = (R^{e, 1}_{m + 1}, \ldots, R^{e, N}_{m + 1})$
for the components for the excess return vector corresponding to each asset that is traded.
If $\omega_m$ is chosen optimally, we decorate it with a $\star$ in the superscript, i.e.
$\omega_m^{\star}$ is the vector of optimal portfolio weights at timestep $m$.
Furthermore, let us assume that the current timestep is denoted by $n$ and let us also define
```math
    \hat W_{M + 1} = W_n R_{n + 1}
        \prod_{m = n + 1}^{M} ((\omega_s^{\star})^\top R^e_{m + 1} + R_{s + 1}).
```

### Result
We assume that the current timestep is denoted by $n$ and that all optimal portfolio weights at
times $m > n$ are known, i.e. $\{\omega_m^\star\}_{m = n + 1}^{M}$ are known.
Assuming the value function $V$ is infinitely differentiable in the first argument, the optimal
portfolio weights $\omega_n^\star$ is the limit of the solutions of the equation indexed by
$k$
```math
\begin{aligned}
    \sum_{r = 1}^{k} \frac{W_t^{r - 1}}{(r - 1)!}  &\Biggl(\sum_{k_1 + \ldots + k_N = r - 1}
    \binom{r - 1}{k_1, \ldots, k_N} \prod_{i=1}^N (\omega_n^i)^{k_i} \times \\
   &\mathbb{E}_n \left[\partial^{r} u(\hat W_{M + 1})
      \prod_{m = n + 1}^{M} ((\omega_m^\star)^\top R^e_{m + 1} + R_{m + 1})^r
      \prod_{i=1}^N (R^i_{n + 1})^{k_i} R^e_{n+1}\right]\Biggr) = 0,
\end{aligned}
```
where $\binom{n}{k_1,\ldots, k_N}$ is the multinomial given by
```math
  \binom{n}{k_1,\ldots, k_N} = \frac{n!}{k_1 ! k_2 ! \cdots k_N !}.
```

Given this result, the pragmatic reader may come up with some reasonable questions:
- How should one choose $k$?
- How should one calculate the conditional expectation value $\mathbb{E}_n[\cdot]$?
- How should one find the optimal portfolio weights $\omega_m^\star$ for $m > n$?

The short and concise answers are:
- The higher $k$, the better. In our experience $4$ suffices for most applications.
- This is done by means of regressions. This can be unstable however.
    Dropping part of the data generated by the integrand $\cdot$ in $\mathbb{E}_n[\cdot]$ seems to partly
    solve this issue.
- This is done by first solving for $\omega_M^\star$. You can then recursively find the solution for
    any time.

If the above does not make sense, do not fret.
This will soon all make sense once we treat the derivation of the above.

## Deriving the solution: so, how do we get there?
The (rough) outline of the derivation is as follows:
1. We prove the value function satisfies the Bellman equation
```math
V_n(W_n, Z_n) = \max_{\omega_n} \mathbb{E}_n[V_{n + 1}(W_{n + 1}, Z_{n + 1})]
```
2. We derive the Taylor expansion the value function $V_{n + 1}$ in the conditional expectation.
    This gives a new expression for $V_n$.
    _Note_: This is where the $k$ came from in the [solution](#result).
3. Using the new expression for $V_n$ we derive the first order conditions of finding the optimal
    $\omega_n$.
4. We manipulate the first order conditions so that all unknown quantities are replaced by
    known quantities.

### The Bellman equation
The value function satisfies the Bellman equation
```math
  V_n(W_n, Z_n) = \max_{\omega_n} \mathbb{E}_n[V_{n + 1}(W_{n + 1}, Z_{n + 1})]
```
with terminal condition $V_{M + 1} (W_{M + 1}, Z_{M + 1}) = u(W_{M + 1})$.

#### Proof
We see that
```math
\begin{aligned}
    V_n(W_n, Z_n)
    &= \max_{\{\omega_m\}_{m = n}^{M}} \mathbb{E}_n\left[ u(W_n) \right]\\
    &= \max_{\omega_n} \max_{\{\omega_m\}_{m = n + 1}^{M}} \mathbb{E}_n\left[ u(W_{M + 1}) \right] \\
    &= \max_{\omega_n} \max_{\{\omega_m\}_{m = n + 1}^{M}}
        \mathbb{E}_n\left[  \mathbb{E}_{n + 1}\left[ u(W_{M + 1}) \right] \right] \\
    &= \max_{\omega_n} \mathbb{E}_n\left[ \max_{\{\omega_m\}_{m = n + 1}^{M}}
        \mathbb{E}_{n + 1}\left[ u(W_{M + 1}) \right] \right] \\
    &= \max_{\omega_n} \mathbb{E}_n\left[ V_{n + 1}(W_{n + 1}, Z_{n + 1}) \right].
\end{aligned}
```
The first equality follows from the definition of the value function.
The second equality follows from separating the maximization over $\omega_t$ and the remaining
maximization over $\{\omega_m\}_{m = n + 1}^{M}$.
The third equality follows from the law of iterated expectations.
The fourth equality follows from the fact that the maximization over
$\{\omega_m\}_{m = n + 1}^{M}$ is independent of the choice of $\omega_n$ and can thus be moved inside the expectation.
And the last equality follows from the definition of the value function at time $t + 1$.

### Taylor expanding the value function
Let us assume that the value function $V$ is $C^(k + 1)$ in the first argument for $k >= 2$.
Then the value function in @value-function satisfies
```math
  V_t(W_t, Z_t)
  = \max_{omega_t} \sum_{n = 0}^{k}
    W_t^n/n!  &\mathbb{E}_t [partial_1^n V_(t + 1)(W_t R_(t + 1), Z_(t + 1)) (omega_t^top R^e_(t + 1))^n ]\
    + W_t^(k+1)/(k+1)! &EE_t [partial_1^(k + 1) V_(t + 1)(xi, Z_(t + 1)) (omega_t^top R^e_(t + 1))^(k + 1) ]
```
for some $xi$ between $W_t R_(t + 1)$ and $W_t (omega_t^top R^e_(t + 1) + R_(t + 1))$.
Here we assume that all moments exist and are finite.








## References
```@bibliography
```